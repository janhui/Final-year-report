
\chapter{Conclusion and Future Work}

\label{ch:conclusions}

In this chapter we reflect on our achievements, summarise the lessons we have learned and describe some potential future works that could be done on the project.

\section{Achievements}

Over the course of this thesis we have seen the evolution of HuddleLamp project through various phases. Setting out with the goal of creating a provisional, portable, interactive table from everyday objects. We can be delighted in the accomplishment of the Device camera application part of the project. The moderate success of the application, demonstrates its potential given better resources.

Furthermore, attempting the project's natural progression to its next milestone gave us valid insights to the potential path it could take. Having researched into various radio frequency signals that were available and eventually selecting and using Bluetooth Low Energy signal to create a tracking and positioning algorithm, enlightened us to the various pitfalls of the idea. Various errors and the problems we faced showed us that, the line of investigation that we were following has limited possibilities and eventually not a practical path to follow.

Identified and implemented a simple API for the data storage module of the application, creating a reusable real-time data storage. Working with the new Firebase API gives us the advantage of a wider community support and meets all our requirement for the applications.

\section{Lessons Learned}

It has been a very enlightening project, giving us the opportunity to investigate into various feature and technologies available. Having spent the vast majority of time on the No camera implementation of project enabled us to learn and understand the different RF signals and types of positioning algorithms associated with them. Giving us a variety of insights into different projects that uses these technologies such as indoor positioning projects. 
Working with BLE technology gave us awareness of the different stack each has on different platforms. It enabled us to harness the technology to our need for the project we had. Learning about the passive listening mode showed us the potential of the technology gave us the chance to work with beacons. Attending a Hackathon dedicated to beacon technology, gave us the chance to see potential applications for the technology and contribute to idea with the knowledge gained from the project.

Creating multiple Android applications to meet the various requirements, gave us the chance to understand the Android platform properly and work with the various sensors that was available to us. We face and overcome a variety of challenges, such as finding the distance from accelerometer to learning concurrency on device with small resources. Giving us the chance to understand the life cycle of an app and creating an efficient application.

By creating the Device camera applications we had to opportunity to work with computer vision libraries, giving us the unique experience of trying to get complicated resource intensive tasks work with small less powerful tools. OpenCV applications are not generally associated with android applications, therefore it was interesting working with OpenCV4Android and improvising to meet some of the objectives of this project and gaining valuable insight into the computer vision research field.

\section{Future Work}

\subsection{Microservice}
Over the course of the device camera implementation, a constant hindrance we faced was the heavy workload taken by the CameraApp. In hindsight, creating a microservice for the vision algorithm, which could be running on a server could have improved the performance. It has a slight chance of not working as well as the current implementation because we would be uploading and analysing the information on a live video. Therefore internet speed could greatly influence the improvement in performance we would get. However it would have been a line of investigation we would have liked to take if given the time.

\subsection{Concurrency}
It would have been interesting to see the difference in the refresh rate of the Device camera, if we had utilised the multi-core facilities available to us on the device. However in truth it would not have improved it significantly. Rough estimation shows that the difference would only have been about 2-3 times better than the current refresh rate. However since the current refresh rate was below 1 frames per second that would not have made too much of a difference.

\subsection{Kalman Filters}
Another feature we would have liked to implement for the positioning algorithm in the no camera implementation a filtering technique. We would have liked to see the impact of techniques like low pass filter or a Kalman filter would have had on the error rate. We believe that although it would not have been good enough to make the positioning technique to work, it would have interesting to see the difference it makes to the system.

\subsection{Devices}
Another interesting investigation would have been trying to use a device with better resource for the CameraApp to see the difference it made. A device such as the Samsung Galaxy Tab S or a Asus Zenfone 4 would have been a good device to try the application with. The difference could be substantial or not at all, however that investigation could shed some light on ways to take the application forward. Especially if we were also investigate decreasing the number of JNI calls we do by creating a single C++ file and investigate using that class.

\subsection{Features}
Currently the Device camera implementation has a subset of functions that HuddleLamp project has. Given more time we would have liked to implement more features such as spatial menus and more gestures onto the project. A feature that would have had a big impact would have been adding something similar to the canvas application we built for the No Camera implementation.

\subsection{Security}
The glaring omission from the current architecture, that would take priority before commercialising this product, would be the lack of security in the application. Currently there is no security features added to the application, anyone can join any sessions deliberately or accidentally. This would have to be rectified by implementing a login or user system with administrative privileges to the organiser of the ``Huddle". There is option for someone to join a system remotely as long as they have a CameraApp and TableApp running in a separate setup and they used the same session name, this is an interesting side-effect of out setup which had to be investigated before deciding whether to keep it or not.

\subsection{Platforms}
Another less priority work would be the porting of the application to different platforms such as iOS and Windows Phone. It would be interesting to see how the application works on a tablet such as the Microsoft Surface Tablet which usually has a much better resource under the hood. Logically, it should give us a better performance. By porting the application we would be expanding the potential user base increasing the probability of the adoption of the product.

\subsection{Nearables}
Something that would that could recover the No Camera implementation is adding instrumentation onto the devices. For instance we could add the Estimote stickers which have their own accelerometer and BLE features and then use the result from both the stickers and the devices to create the positioning algorithm. By comparing and combination multiple values there is a potential to improve the accuracy of the positioning and tracking system. However we have reluctance in adding extra gadgets onto the devices as these are usually not everyday object that people could have laying around.